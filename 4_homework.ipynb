{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41179d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import SplineTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe78e2",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-geometry",
   "metadata": {},
   "source": [
    "## Generate some Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_nonlinear_data(n=None, x=None, noise=0.25, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    if x is None:\n",
    "        x = np.random.uniform(low=0, high=3, size=n)\n",
    "        x[0],x[-1] = 0, 3\n",
    "        y = 3 + (np.sin(3 * x) + 2 * np.sin(2 * x**2) + np.sin(x**3)) / np.exp(x) + np.random.standard_normal(n)*noise       \n",
    "        return x, y\n",
    "    else:\n",
    "        return 3 + (np.sin(3 * x) + 2 * np.sin(2 * x**2) + np.sin(x**3)) / np.exp(x) + np.random.standard_normal(n)*noise     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659420b",
   "metadata": {},
   "source": [
    "### Generate Train, Validation and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fa988",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = give_me_nonlinear_data(n=300, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.6, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0,3.1,0.01)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_train, y_train, label='data points')\n",
    "plt.plot(xx, give_me_nonlinear_data(x=xx, noise=0), color='black', linewidth=3, linestyle='--', label=r'ground truth model $f(x)$')\n",
    "plt.ylabel('y', fontsize=18)\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e3933",
   "metadata": {},
   "source": [
    "# Ridge Regression using Sklearn\n",
    "\n",
    "Our aim to to fit a curve to the above data and balance between the bias and variance to obtain a good model that generalizes to new (unseen) data points.\n",
    "\n",
    "First, we will construct a b-spline basis matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb749ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline = SplineTransformer(degree=3, n_knots=40, include_bias=False).fit(x_train.reshape(-1, 1), y_train)\n",
    "Xtrain = spline.fit_transform(x_train.reshape(-1, 1))\n",
    "Xval = spline.fit_transform(x_val.reshape(-1, 1))\n",
    "Xtest = spline.fit_transform(x_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1396f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b9ce6",
   "metadata": {},
   "source": [
    "Now, we fit a model with a small amount of ridge to predict new data points and plot the corresponding curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80568952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c14f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ridge(alpha=0.005)\n",
    "clf.fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5770ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(0, 3.0,0.001)\n",
    "XX = spline.fit_transform(xx.reshape(-1, 1))\n",
    "yypred = clf.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_train, y_train, label='data points')\n",
    "plt.plot(xx, give_me_nonlinear_data(x=xx, noise=0), color='black', linewidth=3, linestyle='--', label=r'ground truth model $f(x)$')\n",
    "plt.plot(xx, yypred, c='red', linewidth=2, label='regularized curve (not tuned)')\n",
    "plt.ylabel('y', fontsize=18)\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4a6f9",
   "metadata": {},
   "source": [
    "## Exercise 1: Fit a new regularized model (2 points)\n",
    "\n",
    "Let's try to find a smoother fit by regularizing the model. \n",
    "\n",
    "First, to find a good lambda, we can cross-validate the model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42944a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_val = []\n",
    "alphas = []\n",
    "for alpha in np.arange(0, 0.7, 0.01):\n",
    "    reg = # your code\n",
    "    mse_val.append(np.mean((y_val-reg.predict(Xval))**2))\n",
    "    alphas.append(alpha)\n",
    "    \n",
    "idx = np.argmin(mse_val)\n",
    "print(\"alpha=%s, mse val=%s\" %(alphas[idx], mse_val[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bfa546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas[1:], mse_val[1:])\n",
    "plt.ylabel('Validation Error')\n",
    "plt.xlabel('alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b197e",
   "metadata": {},
   "source": [
    "And then we use the suggested alpha to fit a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = # your code\n",
    "clf2.fit(Xtrain, y_train)\n",
    "yypred_reg = clf2.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_train, y_train, label='data points')\n",
    "plt.plot(xx, give_me_nonlinear_data(x=xx, noise=0), color='black', linewidth=3, linestyle='--', label=r'ground truth model $f(x)$')\n",
    "plt.plot(xx, yypred, c='red', linewidth=2, label='fregularized curve (not tuned)')\n",
    "plt.plot(xx, yypred_reg, c='green', linewidth=3, label='regularized curve (tuned)')\n",
    "\n",
    "plt.ylabel('y', fontsize=18)\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c72e24",
   "metadata": {},
   "source": [
    "Finally, let us compare the test error for the unregularized and regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unregularized model', np.sum((y_test-clf.predict(Xtest))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regularized model', np.sum((y_test-clf2.predict(Xtest))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9572b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e1da0d",
   "metadata": {},
   "source": [
    "## Exercise 2:  Implement the Ridge Estimator using the SVD 6 points)\n",
    "Use the Singular Value Decomposition (SVD) of X, to compute the Ridge coefficients. To do so, you can use `numpy.linalg.svd`. \n",
    "\n",
    "You can build on top of the ols class that we have developed previously:\n",
    "* Provide an option to pass the argument `alpha`.\n",
    "* Compute the SVD and use the formula in the notes to compute the coefficients\n",
    "* To obtain the same performance as sklearn, you need to rescale x and y!\n",
    "* Be smart, write a method called `path` that reuses the SVD. The `path` method takes as argument a new alpha, and returns the coefficient vector $\\beta$. This method should reuse the SVD, which was computed during calling the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc77577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRidge:\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        # your code\n",
    "\n",
    "    def fit(self, x, y):\n",
    "       # your code    \n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        # your code\n",
    "    \n",
    "    def path(self, alpha):\n",
    "        # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeeac2b",
   "metadata": {},
   "source": [
    "Use your algorithm to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = myRidge(alpha=0.14)\n",
    "reg.fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regularized model', np.sum((y_test-reg.predict(Xtest))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "yypred_myreg = reg.predict(XX)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x_train, y_train, label='data points')\n",
    "plt.plot(xx, give_me_nonlinear_data(x=xx, noise=0), color='black', linewidth=3, linestyle='--', label=r'ground truth model $f(x)$')\n",
    "plt.plot(xx, yypred_reg, c='red', linewidth=2, label='sklearn')\n",
    "plt.plot(xx, yypred_myreg, c='green', linewidth=3, label='your implementation')\n",
    "\n",
    "plt.ylabel('y', fontsize=18)\n",
    "plt.xlabel('x', fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('model.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a66f7",
   "metadata": {},
   "source": [
    "Now, compute the ridge path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = []\n",
    "for alpha in np.arange(0.1, 5, 0.1):\n",
    "    coef_ = reg.path(alpha=alpha)\n",
    "    beta.append(coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.arange(0.1, 5, 0.1), np.asarray(beta), 'o--')\n",
    "plt.ylim(-2,2)\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('ridge')\n",
    "plt.axhline(y=0, c='black', linewidth=3, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c21ea",
   "metadata": {},
   "source": [
    "The ridge path should look similar to what you get when you use sklearn, but the colors of the lines might differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = []\n",
    "for alpha in np.arange(0.1, 5, 0.1):\n",
    "    skreg = Ridge(alpha=alpha)\n",
    "    skreg = skreg.fit(Xtrain, y_train)\n",
    "    beta.append(skreg.coef_)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.arange(0.1, 5, 0.1), np.asarray(beta), 'o--')\n",
    "plt.ylim(-2,2)\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('ridge')\n",
    "plt.axhline(y=0, c='black', linewidth=3, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85345f4a",
   "metadata": {},
   "source": [
    "If you implemented your algorithm correctly, then you should see that your algorithm is much faster then using sklearn!! (Roughly by a factor of about 15!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "beta = []\n",
    "for alpha in np.arange(0.1, 5, 0.1):\n",
    "    coef_ = reg.path(alpha=alpha)\n",
    "    beta.append(coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "beta = []\n",
    "for alpha in np.arange(0.1, 5, 0.1):\n",
    "    skreg = Ridge(alpha=alpha)\n",
    "    skreg = skreg.fit(Xtrain, y_train)\n",
    "    beta.append(skreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa25f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61035b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4839f261",
   "metadata": {},
   "source": [
    "# Linear Regression on Boston Housing Dataset\n",
    "\n",
    "* First read the following blog post: https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155\n",
    "\n",
    "* Do an Exploratory Data Analysis similar to what is described in the blog post and briefly summarize your observations.\n",
    "\n",
    "* Then, build a simple model that uses only 3 variables and interpret the results. To get full points, your model should have an MSE that is equal to or lower than 4100.\n",
    "\n",
    "* Finally, build a predictive model that best predicts unseen data.  Your predictive model should have an MSE that is equal to or lower than 1400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b443372",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb034cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586452d0",
   "metadata": {},
   "source": [
    "## Exercise 3:  Exploratory Data Analysis  (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2fabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a5171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fef58838",
   "metadata": {},
   "source": [
    "### Summarize your Observations\n",
    "\n",
    "* 1. \n",
    "* 2.\n",
    "* 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38e38e",
   "metadata": {},
   "source": [
    "# Prepare the Data for Subsequent Problems\n",
    "\n",
    "We consider the following subset (for ethical reasons, we do not consider the variable B) that we split into a test, train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e62405",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"CRIM\", \"INDUS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"TAX\", \"PTRATIO\", \"LSTAT\"]\n",
    "x = boston[var_names]\n",
    "y = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc18320",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e670ad2",
   "metadata": {},
   "source": [
    "## Exercise 4: Use the Ridge Path to determine 3 variables that are most expressive (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(np.arange(0.1, 25, 0.1), np.asarray(beta), 'o--')\n",
    "plt.ylabel('beta')\n",
    "plt.xlabel('ridge')\n",
    "plt.axhline(y=0, c='black', linewidth=3, linestyle='dashed')\n",
    "plt.legend(var_names, loc=1, fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b152523",
   "metadata": {},
   "source": [
    "Write down the variable names that you suggest to use:\n",
    "* var 1\n",
    "* var 2\n",
    "* var 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd606402",
   "metadata": {},
   "source": [
    "## Exercise 5:  Fit a simple model with 3 variables (3 points)\n",
    "\n",
    "Build a simple model that uses the 3 most relevant variables and interpret the estimated coefficients. Use the bootstrap method to test whether the estimated parameters are significant different from 0.  Your model should have an MSE that is equal to or lower than 4100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefcdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_id = [0, 1, 2] # you need to chose the right indicies depending on your analyis above ....\n",
    "x_train_sub = x_train[:,subset_id]\n",
    "x_test_sub = x_test[:,subset_id]\n",
    "x_val_sub = x_val[:,subset_id]\n",
    "\n",
    "x_train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "skreg = Ridge(alpha=0.0)\n",
    "skreg = skreg.fit(x_train_sub, y_train)\n",
    "skreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7589472",
   "metadata": {},
   "source": [
    "Compute the MSE on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE', np.sum((y_test-skreg.predict(x_test_sub))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ecc63",
   "metadata": {},
   "source": [
    "Now, use the bootstrap method to check whether all coefficient are statistical significant. We say a coefficient is significant if the 95% bootstrap confidence interval does not contain zero. We indicate the lower 0.025 and upper 0.975 quantiles by red bars below.  \n",
    "\n",
    "* https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/\n",
    "* https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skreg = Ridge(alpha=0.0)\n",
    "beta = []\n",
    "for i in range(2500):\n",
    "    idx = np.random.choice(len(x_train_sub), len(x_train_sub), replace=True)\n",
    "    beta.append(np.asarray(skreg.fit(x_train_sub[idx], y_train[idx]).coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b78a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.asarray(beta)\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37544ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(data=beta[:,0])\n",
    "plt.axvline(x=np.quantile(beta[:,0],0.025), c='red')\n",
    "plt.axvline(x=np.quantile(beta[:,0],0.975), c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44911e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for variable 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code vor variable 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c083a",
   "metadata": {},
   "source": [
    "Discuss your results:\n",
    "* Are the signs of the coefficients practically significant?\n",
    "* Are the coefficients statistical significant?\n",
    "* Does a model with only 2 variables do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fbb10",
   "metadata": {},
   "source": [
    "This is a bonus material, but you can also look to the partial residual plots. (https://www.statsmodels.org/dev/examples/notebooks/generated/regression_plots.html) You will see that the model is slightly misspecified, but real data are never going to be perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f663f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "regr = OLS(y_train, add_constant(x_train_sub)).fit()\n",
    "print(regr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "fig = plt.figure(figsize=(18,7))\n",
    "fig = sm.graphics.plot_partregress_grid(regr)\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666afad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a187811a",
   "metadata": {},
   "source": [
    "## Exercise 6:  Build a predictive model (4 points)\n",
    "\n",
    "The aim it to build a model that generalizes well to new data. You can use all variables or a subset of the variables and should also do some feature preprocessing. For instance, try \n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "To get full points, your model should achieve an MSE below 1400 on the test set! But, it is not too difficult to get a model that achieves an MSE below 1200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300af59d",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a68f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_id = # your code\n",
    "x_train_sub = x_train[:,subset_id]\n",
    "x_test_sub = x_test[:,subset_id]\n",
    "x_val_sub = x_val[:,subset_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e79c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code, maybe do some data transformations here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17217c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some tuning on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = Ridge(alpha=0.0)\n",
    "pred_model.fit(# your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6075244",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE', np.sum((y_test-pred_model.predict( your_array ))**2)) #replace your_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
